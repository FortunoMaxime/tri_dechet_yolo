from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
import cv2
import numpy as np
import uvicorn
from ultralytics import YOLO
import base64
import io
from PIL import Image
import json
from typing import List, Dict, Any, Optional
import asyncio
import threading
from pathlib import Path
import settings
import helper

# Configuration FastAPI
app = FastAPI(
    title="Waste Classification Mobile API",
    description="API mobile pour la classification des d√©chets avec YOLOv8",
    version="2.0.0"
)

# Middleware CORS pour React Native
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# √âtat global pour le streaming
camera_active = False
current_frame = None
camera_lock = threading.Lock()

# Charger le mod√®le
try:
    model = helper.load_model('weights/yoloooo.pt')
    print("‚úÖ Mod√®le YOLO charg√© avec succ√®s")
except Exception as e:
    print(f"‚ùå Erreur chargement mod√®le: {e}")
    model = None

# Mod√®les Pydantic pour la validation
from pydantic import BaseModel

class DetectionRequest(BaseModel):
    confidence: float = 0.5
    image: Optional[str] = None

class DetectionResponse(BaseModel):
    success: bool
    detections: List[Dict[str, Any]]
    count: int
    image_with_boxes: Optional[str] = None
    message: str = ""

class WebcamStatus(BaseModel):
    active: bool
    message: str

# Routes de l'API
@app.get("/")
async def root():
    return {
        "message": "Waste Classification Mobile API",
        "endpoints": {
            "health": "/api/health",
            "detect_image": "/api/detect/image",
            "detect_upload": "/api/detect/upload", 
            "webcam_start": "/api/webcam/start",
            "webcam_stop": "/api/webcam/stop",
            "webcam_stream": "/api/webcam/stream",
            "model_info": "/api/model/info"
        }
    }

@app.get("/api/health")
async def health_check():
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "camera_active": camera_active
    }

@app.get("/api/model/info")
async def model_info():
    """Informations sur le mod√®le charg√©"""
    if model is None:
        raise HTTPException(status_code=500, detail="Model not loaded")
    
    return {
        "model_name": "YOLOv8 Waste Classification",
        "classes": model.names if hasattr(model, 'names') else {},
        "input_size": getattr(model, 'imgsz', 640)
    }

@app.post("/api/detect/image", response_model=DetectionResponse)
async def detect_image(request: DetectionRequest):
    """D√©tection sur image base64"""
    try:
        if model is None:
            raise HTTPException(status_code=500, detail="Model not loaded")
        
        if not request.image:
            raise HTTPException(status_code=400, detail="No image provided")
        
        # D√©coder l'image base64
        image_data = request.image
        if 'base64,' in image_data:
            image_data = image_data.split('base64,')[1]
        
        image_bytes = base64.b64decode(image_data)
        image = Image.open(io.BytesIO(image_bytes))
        img_np = np.array(image)
        
        return await process_detection(img_np, request.confidence)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/detect/upload", response_model=DetectionResponse)
async def detect_upload(
    file: UploadFile = File(...),
    confidence: float = 0.5
):
    """D√©tection sur fichier upload√©"""
    try:
        if model is None:
            raise HTTPException(status_code=500, detail="Model not loaded")
        
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="File must be an image")
        
        # Lire et convertir l'image
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        img_np = np.array(image)
        
        return await process_detection(img_np, confidence)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

async def process_detection(img_np: np.ndarray, confidence: float) -> DetectionResponse:
    """Traite la d√©tection et retourne les r√©sultats"""
    try:
        # Conversion BGR pour OpenCV
        if len(img_np.shape) == 3 and img_np.shape[2] == 3:
            img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
        
        # Pr√©diction YOLO
        results = model.predict(img_np, conf=confidence)
        
        detections = []
        result_image = img_np.copy()
        
        for r in results:
            boxes = r.boxes
            if boxes is not None:
                # Dessiner les bo√Ætes sur l'image
                result_image = r.plot()
                
                for box in boxes:
                    detection = {
                        'class': model.names[int(box.cls)],
                        'class_id': int(box.cls),
                        'confidence': float(box.conf),
                        'bbox': box.xywhn[0].tolist() if box.xywhn.numel() > 0 else [],
                        'bbox_pixels': box.xyxy[0].tolist() if box.xyxy.numel() > 0 else []
                    }
                    detections.append(detection)
        
        # Convertir l'image r√©sultat en base64
        _, buffer = cv2.imencode('.jpg', result_image)
        image_base64 = base64.b64encode(buffer).decode('utf-8')
        
        return DetectionResponse(
            success=True,
            detections=detections,
            count=len(detections),
            image_with_boxes=image_base64,
            message=f"{len(detections)} objets d√©tect√©s" if detections else "Aucun objet d√©tect√©"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur traitement: {str(e)}")

# Fonctions pour le streaming webcam
def webcam_stream_task(confidence: float):
    """Thread pour capturer le flux webcam"""
    global camera_active, current_frame
    
    try:
        cap = cv2.VideoCapture(settings.WEBCAM_PATH)
        
        while camera_active:
            ret, frame = cap.read()
            if ret:
                # Redimensionner pour performance mobile
                frame = cv2.resize(frame, (640, 480))
                
                # D√©tection en temps r√©el
                results = model.predict(frame, conf=confidence)
                
                # Dessiner les r√©sultats
                for r in results:
                    frame = r.plot()
                
                with camera_lock:
                    current_frame = frame
            else:
                break
            
            # Limiter √† ~10 FPS
            cv2.waitKey(100)
        
        cap.release()
        print("üìπ Stream webcam arr√™t√©")
        
    except Exception as e:
        print(f"‚ùå Erreur webcam: {e}")
        camera_active = False

@app.post("/api/webcam/start")
async def webcam_start(confidence: float = 0.5):
    """D√©marrer le streaming webcam"""
    global camera_active
    
    if camera_active:
        return {"status": "already_active", "message": "Webcam d√©j√† active"}
    
    if model is None:
        raise HTTPException(status_code=500, detail="Model not loaded")
    
    camera_active = True
    # D√©marrer le thread webcam
    thread = threading.Thread(target=webcam_stream_task, args=(confidence,))
    thread.daemon = True
    thread.start()
    
    return {
        "status": "started", 
        "message": "Webcam d√©marr√©e",
        "confidence": confidence
    }

@app.post("/api/webcam/stop")
async def webcam_stop():
    """Arr√™ter le streaming webcam"""
    global camera_active
    camera_active = False
    
    return {
        "status": "stopped",
        "message": "Webcam arr√™t√©e"
    }

@app.get("/api/webcam/status")
async def webcam_status():
    """Statut du streaming webcam"""
    return WebcamStatus(
        active=camera_active,
        message="Webcam active" if camera_active else "Webcam inactive"
    )

@app.get("/api/webcam/stream")
async def webcam_stream():
    """Streaming MJPEG pour la webcam"""
    async def generate_frames():
        while camera_active:
            with camera_lock:
                if current_frame is not None:
                    # Encoder en JPEG
                    _, buffer = cv2.imencode('.jpg', current_frame)
                    frame_data = buffer.tobytes()
                    
                    yield (b'--frame\r\n'
                           b'Content-Type: image/jpeg\r\n\r\n' + frame_data + b'\r\n')
            
            await asyncio.sleep(0.1)  # ~10 FPS
    
    return StreamingResponse(
        generate_frames(),
        media_type="multipart/x-mixed-replace; boundary=frame"
    )

@app.get("/api/webcam/frame")
async def webcam_frame():
    """R√©cup√©rer une frame unique de la webcam"""
    if not camera_active:
        raise HTTPException(status_code=400, detail="Webcam not active")
    
    with camera_lock:
        if current_frame is None:
            raise HTTPException(status_code=404, detail="No frame available")
        
        _, buffer = cv2.imencode('.jpg', current_frame)
        image_base64 = base64.b64encode(buffer).decode('utf-8')
        
        return {
            "success": True,
            "image": image_base64,
            "timestamp": asyncio.get_event_loop().time()
        }

# Routes pour les vid√©os stock√©es
@app.get("/api/videos/list")
async def list_videos():
    """Liste des vid√©os disponibles"""
    videos = []
    for name, path in settings.VIDEOS_DICT.items():
        if Path(path).exists():
            videos.append({
                "name": name,
                "path": str(path),
                "display_name": name.replace('_', ' ').title()
            })
    
    return {"videos": videos}

@app.post("/api/videos/detect/{video_name}")
async def detect_video(video_name: str, confidence: float = 0.5):
    """D√©tection sur une vid√©o stock√©e"""
    try:
        if model is None:
            raise HTTPException(status_code=500, detail="Model not loaded")
        
        if video_name not in settings.VIDEOS_DICT:
            raise HTTPException(status_code=404, detail="Video not found")
        
        video_path = settings.VIDEOS_DICT[video_name]
        cap = cv2.VideoCapture(str(video_path))
        
        if not cap.isOpened():
            raise HTTPException(status_code=400, detail="Cannot open video")
        
        # Traiter la premi√®re frame pour d√©monstration
        success, frame = cap.read()
        if success:
            response = await process_detection(frame, confidence)
            cap.release()
            return response
        else:
            cap.release()
            raise HTTPException(status_code=400, detail="Cannot read video frame")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Gestion des erreurs globales
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    return JSONResponse(
        status_code=500,
        content={"success": False, "error": str(exc)}
    )

if __name__ == "__main__":
    uvicorn.run(
        "fastapi_app:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )